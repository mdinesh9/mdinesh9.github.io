<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Dinesh's Journal - Distributed Systems</title><link href="http://localhost:8000/" rel="alternate"></link><link href="http://localhost:8000/feeds/distributed-systems.atom.xml" rel="self"></link><id>http://localhost:8000/</id><updated>2018-08-21T00:00:00+05:30</updated><entry><title>Distributed Systems / Cloud Patterns - Circuit Breaker for Non-Transient failures</title><link href="http://localhost:8000/pattern-distributed-cloud-issues-circuit-breaker.html" rel="alternate"></link><published>2018-08-21T00:00:00+05:30</published><updated>2018-08-21T00:00:00+05:30</updated><author><name>Dinesh</name></author><id>tag:localhost,2018-08-21:/pattern-distributed-cloud-issues-circuit-breaker.html</id><summary type="html">&lt;p&gt;How to hande network issues in distributed systems and cloud environment.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Non-transient(non temporary) failures in distributed systems are issues that usually persist for a very long time, may take longer to recover, and can even make the system unavailable. &lt;/p&gt;
&lt;p&gt;We already discussed about retry pattern in the previous blog post, but retry pattern cannot handle non-transient failures.&lt;/p&gt;
&lt;p&gt;The problem with non-transcient failures is that it can make many services go down when they are dependent on each other.&lt;/p&gt;
&lt;p&gt;For example, look at the below image where Service 3 &amp;amp; 2 requires Service 1 to succeed and Service 4 requires Service 3 to succeed.&lt;/p&gt;
&lt;p&gt;This is deadly and can cause entire system to break down.&lt;/p&gt;
&lt;p&gt;&lt;img alt="transcient_failure_causes_dependecy_failures" src="images/../../images/retry_pattern/circuit_breaker_dependency_failure.png"&gt;&lt;/p&gt;
&lt;p&gt;It is not just the database that might long time to recover. It can also be that the service that has to respond is hammered with lot of requessts. &lt;/p&gt;
&lt;p&gt;Some common causes of non-transient failures include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Network Congestion&lt;/li&gt;
&lt;li&gt;Reboot failures&lt;/li&gt;
&lt;li&gt;Resource blockages/ Exhaustion, when other services are utilizing a service that we might be calling. During this resource exhaustion can happen such as CPU, memory, and storage are not sufficent anymore.&lt;/li&gt;
&lt;li&gt;Outages that last very long&lt;/li&gt;
&lt;li&gt;Dependency failures&lt;/li&gt;
&lt;li&gt;Hardware issues, such as network cable was severed etc. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is not advised to keep retrying during non-transient failures, because we put a lot of load on the servers, waste lot of computing resources, and we are just waiting out for the issue to resolve. &lt;/p&gt;
&lt;p&gt;So how do we handle the non-transcient failures?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We stop requests to the failing server for some time until it recovers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unlike retry pattern, a Circuit Breaker sits in between the client &amp;amp; the server.&lt;/p&gt;
&lt;p&gt;&lt;img alt="circuit_breaker_position" src="images/../../images/retry_pattern/circuit_breaker_position.png"&gt;&lt;/p&gt;
&lt;p&gt;Circuit breaker will allow the failing component, some time to recover, thereby also conserving resources.&lt;/p&gt;
&lt;p&gt;A Circuit Breaker can be at different types of states:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Closed circuit:&lt;ul&gt;
&lt;li&gt;This is the first state of the Circuit breaker where it is closed and it is allowing request to pass from one service to another service, and the communication/response is successful.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Open circuit:&lt;ul&gt;
&lt;li&gt;This can be the second state of the Circuit breaker where two services are unable to communicate, as in response received is failure. So, the circuit is open disallowing the connection from one service to another.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Half Open circuit:&lt;ul&gt;
&lt;li&gt;This can be the third state, and occurs only when Open Circuit occurs.&lt;/li&gt;
&lt;li&gt;This state can be used for testing, where a Service sends test request to another service to test the connection and if it is working, then the state goes to Closed circuit state or else, it will remain in the Open circuit state.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="circuit_breaker_states" src="images/../../images/retry_pattern/circuit_breaker_states.png"&gt;&lt;/p&gt;</content><category term="Distributed Systems"></category><category term="Distributed Systems"></category><category term="Micro Services"></category><category term="Patterns"></category><category term="Circuit Breaker"></category></entry><entry><title>Distributed Systems / Cloud Patterns - Retry for Transient failures</title><link href="http://localhost:8000/pattern-distributed-cloud-transient-issues-retry.html" rel="alternate"></link><published>2018-08-09T00:00:00+05:30</published><updated>2018-08-09T00:00:00+05:30</updated><author><name>Dinesh</name></author><id>tag:localhost,2018-08-09:/pattern-distributed-cloud-transient-issues-retry.html</id><summary type="html">&lt;p&gt;How to handle transient issues in distributed systems and cloud environment.&lt;/p&gt;</summary><content type="html">&lt;p&gt;We use retry pattern when dealing a temporary failure(also called transient failure), and retrying will fix the issue.&lt;/p&gt;
&lt;p&gt;Transient failures are temporary errors that occur in distributed systems. They can be caused by a variety of factors, such as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Network Problems: can be due to packet loss, routing errors, and timeouts.&lt;/li&gt;
&lt;li&gt;Software Failures: due to crashes, memory leaks, and crashes&lt;/li&gt;
&lt;li&gt;Resource failures: Temporary unavailability of a VM or disk, and Cold start problems in Serverless instances etc.&lt;/li&gt;
&lt;li&gt;Infrastructure failures: Such as power outages, and hardware issues.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We should handle transient failures, otherwise, these issues can cause decreased throughput, increased latency, outages, pipeline failures etc.&lt;/p&gt;
&lt;p&gt;So, our code should be resilient enough to handle transient failures, using various stragegies listed below to overcome transient failures. &lt;/p&gt;
&lt;p&gt;Retry Strategies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;retries the naive way&lt;/li&gt;
&lt;li&gt;retry specific number of times and fail&lt;/li&gt;
&lt;li&gt;backoff ( sometimes used, after the above fails, )&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- - Logging retry patterns  [TODO] --&gt;

&lt;p&gt;Lets talk in detail about these patterns:&lt;/p&gt;
&lt;h5&gt;1. Retry:&lt;/h5&gt;
&lt;p&gt;You keep hammering the server or a service or an API call, until the issue resolves. No delays, no time delays!&lt;/p&gt;
&lt;p&gt;Examples can be database connections, failed request call between two services etc.&lt;/p&gt;
&lt;p&gt;Drawing below shows how this works:&lt;/p&gt;
&lt;p&gt;&lt;img alt="retry_pattern_mlops_logo" src="images/../../images/retry_pattern/retry-pattern-mlops-micro-services.png"&gt;&lt;/p&gt;
&lt;h5&gt;2. Retry Specific number of times:&lt;/h5&gt;
&lt;p&gt;We implement this strategy when we dont want to hammer the server. For example, we retry for 4 times and then stop.&lt;/p&gt;
&lt;p&gt;Drawing below shows how this works:&lt;/p&gt;
&lt;p&gt;&lt;img alt="retry_pattern_mlops_logo" src="images/../../images/retry_pattern/retry_only_specific_numberoftimes.png"&gt;&lt;/p&gt;
&lt;h5&gt;3. Retry with Backoff:&lt;/h5&gt;
&lt;p&gt;We usually use Retry with Backoff, when the previous method fails where we retry for a specific number of times.&lt;/p&gt;
&lt;p&gt;Whenever you face an issue, you keep retrying, with increased sleep delays.&lt;/p&gt;
&lt;p&gt;We add increased sleep delays everytime, to reduce the load that we put on the server.&lt;/p&gt;
&lt;p&gt;Drawing below shows how this works:&lt;/p&gt;
&lt;p&gt;&lt;img alt="retry_pattern_mlops_logo" src="images/../../images/retry_pattern/retry_with_backoff.png"&gt;&lt;/p&gt;
&lt;p&gt;In the next blog post, we will discuss about Circuit Breaker pattern, which is a pattern that can be used to handle non-transient failures.&lt;/p&gt;</content><category term="Distributed Systems"></category><category term="Distributed Systems"></category><category term="Micro Services"></category><category term="Patterns"></category><category term="Retry"></category></entry></feed>